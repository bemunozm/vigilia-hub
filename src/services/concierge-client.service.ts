import WebSocket from 'ws';
import axios from 'axios';
import { Logger } from '../utils/logger';
import { WebSocketClientService } from './websocket-client.service';

/**
 * Cliente para OpenAI Realtime API usando WebSocket directo
 * R√©plica exacta del flujo del frontend (DigitalConciergeView.tsx)
 * 
 * Implementaci√≥n: WebSocket nativo (ws library)
 * Referencia: https://platform.openai.com/docs/api-reference/realtime
 */
export class ConciergeClientService {
  private readonly logger = new Logger(ConciergeClientService.name);
  private ws: WebSocket | null = null;
  private currentSessionId: string | null = null;
  private conversationActive = false;
  private backendUrl: string;
  private audioHandlers: ((audioBuffer: Buffer) => void)[] = [];
  private audioDoneHandlers: (() => void)[] = [];
  private speechStartedHandlers: (() => void)[] = [];
  private conversationEndedHandlers: (() => void)[] = []; // <-- NUEVO
  private targetHouse: string | null = null;
  private isInterrupted = false;
  private isResponseActive = false; // <-- NUEVO: Para saber si vale la pena cancelar
  
  // Configuraci√≥n del modelo Realtime (versi√≥n GA estable)
  private readonly REALTIME_MODEL = 'gpt-realtime-mini-2025-12-15';
  private readonly REALTIME_WS_URL = 'wss://api.openai.com/v1/realtime';

  constructor(
    private readonly websocketClient: WebSocketClientService
  ) {
    const backendUrl = process.env.BACKEND_API_URL;
    
    if (!backendUrl) {
      throw new Error('BACKEND_API_URL no configurado en .env');
    }

    this.backendUrl = backendUrl;
    this.logger.log('‚úÖ Concierge Client inicializado (WebSocket nativo)');
    this.logger.log(`üì° Backend URL: ${this.backendUrl}`);
    this.logger.log(`ü§ñ Modelo: ${this.REALTIME_MODEL}`);
  }

  /**
   * Conecta a OpenAI Realtime API usando WebSocket directo
   */
  async connect(): Promise<void> {
    try {
      let ephemeralToken: string;
      let sessionId: string;

      // üîç DEBUG: Permitir uso directo de API Key para descartar problemas de tokens ef√≠meros
      if (process.env.DEBUG_OPENAI_KEY) {
        this.logger.warn('‚ö†Ô∏è MODO DEBUG ACTIVADO: Usando API Key directa (Bypassing Backend) ‚ö†Ô∏è');
        ephemeralToken = process.env.DEBUG_OPENAI_KEY;
        sessionId = `debug_${Date.now()}`;
        this.currentSessionId = sessionId;
      } else {
        this.logger.log('üé´ Solicitando token ef√≠mero al backend...');
        
        // Obtener token ef√≠mero y sessionId del backend
        const response = await axios.post(`${this.backendUrl}/api/v1/concierge/session/start`, {
          socketId: this.websocketClient.getSocketId(),
        });

        ephemeralToken = response.data.ephemeralToken;
        sessionId = response.data.sessionId;
        this.currentSessionId = sessionId;
        this.logger.log(`‚úÖ Token ef√≠mero obtenido. SessionId: ${sessionId}`);
      }
      
      this.logger.log('ü§ñ Conectando a OpenAI Realtime API via WebSocket...');

      // Construir URL con modelo y headers seg√∫n documentaci√≥n OpenAI
      const wsUrl = `${this.REALTIME_WS_URL}?model=${this.REALTIME_MODEL}`;
      
      // Crear WebSocket con headers de autorizaci√≥n
      this.ws = new WebSocket(wsUrl, {
        headers: {
          'Authorization': `Bearer ${ephemeralToken}`,
        }
      });

      // Configurar event handlers
      this.setupEventHandlers();

      // Esperar a que el WebSocket est√© abierto
      await new Promise<void>((resolve, reject) => {
        const timeout = setTimeout(() => {
          reject(new Error('Timeout esperando conexi√≥n WebSocket'));
        }, 10000);

        this.ws!.on('open', () => {
          clearTimeout(timeout);
          this.logger.log('‚úÖ WebSocket conectado a OpenAI Realtime API');
          this.configureSession();
          resolve();
        });

        this.ws!.on('error', (error: Error) => {
          clearTimeout(timeout);
          this.logger.error('‚ùå Error en WebSocket de OpenAI:', error);
          reject(error);
        });
      });

      // === NUEVO: Suscribirse a los eventos del WebSocket del Backend ===
      this.subscribeToBackendEvents(sessionId);

    } catch (error) {
      this.logger.error('‚ùå Error conectando a OpenAI:', error);
      if (axios.isAxiosError(error)) {
        this.logger.error(`Detalles del error HTTP: ${error.response?.status} - ${JSON.stringify(error.response?.data)}`);
      }
      throw error;
    }
  }

  /**
   * Suscribe a los eventos del backend para la sesi√≥n actual
   */
  private subscribeToBackendEvents(sessionId: string): void {
      const eventName = `visitor:response:${sessionId}`;
      
      this.websocketClient.onEvent(eventName, (data: any) => {
          this.logger.log(`üîî Evento de residente recibido! Decisi√≥n: ${data.approved ? 'APROBADA' : 'RECHAZADA'}`);
          
          if (!this.conversationActive) {
             this.logger.warn('Se recibi√≥ la decisi√≥n, pero la conversaci√≥n ya hab√≠a terminado.');
             return;
          }

          // Inyectar el mensaje del sistema notificando la decisi√≥n
          this.sendEvent({
              type: 'conversation.item.create',
              item: {
                  type: 'message',
                  role: 'system',
                  content: [
                      {
                          type: 'input_text',
                          text: `ATENCI√ìN: EL SISTEMA HA RECIBIDO LA RESPUESTA DEL RESIDENTE. La visita ha sido ${data.approved ? 'APROBADA (Debe ingresar)' : 'RECHAZADA (No debe ingresar)'}. Procede INMEDIATAMENTE al paso 5 del flujo y d√°selo a conocer al visitante basado en esta respuesta oficial.`
                      }
                  ]
              }
          });

          // Forzar la generaci√≥n de la respuesta
          this.sendEvent({ type: 'response.create' });
      });
  }

  /**
   * Configura la sesi√≥n de OpenAI con par√°metros optimizados
   * Estructura seg√∫n documentaci√≥n oficial de OpenAI Realtime API
   */
  private configureSession(): void {
    if (!this.ws) {
      this.logger.error('‚ùå No hay WebSocket para configurar');
      return;
    }

    // Configuraci√≥n de sesi√≥n seg√∫n documentaci√≥n oficial
    // ESTRATEGIA DEBUG: Agregar type='realtime' aunque no debiera ser necesario para update, por si acaso es el param faltante.
    const sessionConfig = {
      type: 'session.update',
      session: {
        // CORRECCION CRITICA: El API rechaza "modalities", usa "modalities" en Beta pero "output_modalities" en GA WebSocket object?
        // El log del backend muestra "output_modalities": ["audio"].
        // Intentaremos usar "modalities" -> "output_modalities" (como estaba al inicio) ya que "modalities" fall√≥.
        // Ademas mantenemos type='realtime' que solucion√≥ el error de parametro requerido.
        type: 'realtime', 
        
        // modalities: ['audio', 'text'], // ESTO FALL√ì ("Unknown parameter")
        // Probamos sin modalities expl√≠cito para ver si toma default, o usamos output_modalities si queremos cambiarlo.
        // Vamos a comentar modalities para que no falle el update. Las tools deber√≠an funcionar igual.
        // Si no hay texto, tal vez no pueda emitir function calls? 
        // Pero "output_modalities": ["audio"] es el default y function calling funciona con audio inputs.
        // Vamos a probar SIN este campo para asegurar que session.update pase sin error.
        
        // NOTA: Eliminamos 'voice' temporalmente porque lanza "Unknown parameter".
        // Usaremos la voz por defecto ('alloy') por ahora para asegurar conexi√≥n.
        
        instructions: this.getSystemInstructions(),
        
        // Estructura anidada 'audio' siguiendo RealtimeAudioConfig
        audio: {
          input: {
            // El formato debe ser un objeto con type 'audio/pcm' y rate 24000
            format: { 
              type: 'audio/pcm',
              rate: 24000
            },
            transcription: {
              // Usamos el modelo de transcripci√≥n optimizado para la versi√≥n Mini (whisper-1 puede tener rate limits estrictos)
              model: 'gpt-4o-mini-transcribe-2025-12-15', 
              language: 'es'
            },
            turn_detection: {
              type: 'server_vad',
              threshold: 0.8, // (Antes 0.5). M√°s alto => Menos sensible al ruido de calle/bocinas
              prefix_padding_ms: 300,
              silence_duration_ms: 350, 
              create_response: true,
              interrupt_response: true // Que el servidor cancele autom√°ticamente
            }
          },
          output: {
            // El formato de salida tambi√©n debe ser objeto
            format: { 
              type: 'audio/pcm',
              rate: 24000
            },
            voice: 'sage'
          }
        },
        
        tools: this.getToolDefinitions(),
        tool_choice: 'auto',
      }
    };

    this.logger.log('üì§ Enviando configuraci√≥n de sesi√≥n:', JSON.stringify(sessionConfig, null, 2));
    this.sendEvent(sessionConfig);

    this.logger.log('üìã Sesi√≥n de OpenAI configurada exitosamente');
  }

  /**
   * Instrucciones del sistema para el Conserje Digital
   * Instrucciones base - el contexto espec√≠fico se agrega despu√©s
   */
  private getSystemInstructions(): string {
    return 'Act√∫a como la interfaz de voz del sistema de control de acceso Vigilia. Espera instrucciones espec√≠ficas del contexto.';
  }

  /**
   * Define las herramientas disponibles
   * R√©plica exacta del frontend
   */
  private getToolDefinitions(): any[] {
    return [
      {
        type: 'function',
        name: 'guardar_datos_visitante',
        description: 'Guarda y formatea autom√°ticamente los datos del visitante. El RUT se formatea a XX.XXX.XXX-X, el tel√©fono se limpia de caracteres especiales, y la patente se normaliza a may√∫sculas.',
        parameters: {
          type: 'object',
          properties: {
            nombre: {
              type: 'string',
              description: 'Nombre completo del visitante tal como lo dijo'
            },
            rut: {
              type: 'string',
              description: 'RUT o pasaporte del visitante en cualquier formato (n√∫meros, con/sin puntos o gui√≥n)'
            },
            telefono: {
              type: 'string',
              description: 'Tel√©fono del visitante en cualquier formato'
            },
            patente: {
              type: 'string',
              description: 'Patente del veh√≠culo en cualquier formato'
            },
            motivo: {
              type: 'string',
              description: 'Motivo de la visita'
            },
            casa: {
              type: 'string',
              description: 'N√∫mero de casa/departamento de destino'
            }
          }
        }
      },
      {
        type: 'function',
        name: 'buscar_residente',
        description: 'Busca un residente por n√∫mero o c√≥digo de casa/departamento. Acepta m√∫ltiples formatos: n√∫meros solos ("15"), con prefijos ("Casa 15"), o c√≥digos alfanum√©ricos ("A-1234", "B-201"). Devuelve TODOS los residentes de la familia.',
        parameters: {
          type: 'object',
          properties: {
            casa: {
              type: 'string',
              description: 'N√∫mero, c√≥digo o nombre de casa/departamento tal como lo dijo el visitante'
            }
          },
          required: ['casa']
        }
      },
      {
        type: 'function',
        name: 'notificar_residente',
        description: 'Env√≠a una notificaci√≥n push a TODOS los residentes de la familia para que aprueben o rechacen la visita',
        parameters: {
          type: 'object',
          properties: {
            residentes_ids: {
              type: 'array',
              items: {
                type: 'string'
              },
              description: 'Array con los IDs de TODOS los residentes a notificar (todos los miembros de la familia)'
            }
          },
          required: ['residentes_ids']
        }
      },
      {
        type: 'function',
        name: 'finalizar_llamada',
        description: 'Finaliza la llamada con el visitante. Usa esta herramienta SOLO despu√©s de despedirte completamente. NO menciones que est√°s finalizando la llamada, solo desp√≠dete naturalmente.',
        parameters: {
          type: 'object',
          properties: {}
        }
      }
    ];
  }

  /**
   * M√©todo auxiliar para enviar eventos al WebSocket
   */
  private sendEvent(event: any): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      this.logger.error('‚ùå WebSocket no est√° abierto, no se puede enviar evento');
      return;
    }

    const eventString = JSON.stringify(event);
    this.ws.send(eventString);
  }

  /**
   * Event handlers para WebSocket directo
   * R√©plica exacta del frontend
   */
  private setupEventHandlers(): void {
    if (!this.ws) return;

    // Mensaje recibido del WebSocket
    this.ws.on('message', (data: WebSocket.Data) => {
      try {
        const event = JSON.parse(data.toString());
        this.handleRealtimeEvent(event);
      } catch (error) {
        this.logger.error('‚ùå Error parseando mensaje de WebSocket:', error);
      }
    });

    // WebSocket cerrado
    this.ws.on('close', (code: number, reason: Buffer) => {
      this.logger.warn(`‚ùå Conexi√≥n a OpenAI cerrada - C√≥digo: ${code}, Raz√≥n: ${reason.toString()}`);
      this.conversationActive = false;
    });

    // Error en WebSocket
    this.ws.on('error', (error: Error) => {
      this.logger.error('‚ùå Error en WebSocket:', error);
    });
  }

  /**
   * Maneja eventos de la Realtime API
   */
  private handleRealtimeEvent(event: any): void {
    const { type } = event;

    // Filtrar eventos ruidosos (deltas)
    if (!type.includes('delta') && !type.includes('input_audio_buffer')) {
      this.logger.log(`üì• Evento: ${type}`, JSON.stringify(event, null, 2));
    }

    switch (type) {
      // Sesi√≥n
      case 'session.created':
        this.logger.log(`‚úÖ Sesi√≥n creada: ${event.session?.id}`);
        break;

      case 'session.updated':
        this.logger.log('‚úÖ Sesi√≥n actualizada correctamente');
        break;

      // Respuestas
      case 'response.created':
        this.logger.log(`üé¨ Respuesta iniciada: ${event.response?.id}`);
        this.isInterrupted = false; // Nueva respuesta, resetear flag
        this.isResponseActive = true; // <-- NUEVO
        break;

      case 'response.done':
        this.logger.log(`‚úÖ Respuesta completa: ${event.response?.id}`);
        this.logger.log('Detalles:', JSON.stringify(event.response, null, 2));
        this.isResponseActive = false; // <-- NUEVO
        break;

      case 'response.content_part.added':
        this.logger.log(`üìù Content part agregado: ${event.part?.type}`);
        break;

      case 'response.output_item.added':
        this.logger.log(`üìù Output item agregado: ${event.item?.type}`);
        break;

      case 'response.output_item.done':
        this.logger.log(`‚úÖ Output item completado: ${event.item?.type}`);
        break;

      // Audio
      case 'response.audio.delta':
      case 'response.output_audio.delta':
        if (this.isInterrupted) {
          // Ignorar audio si el usuario interrumpi√≥
          return;
        }
        this.logger.debug('üîä Audio delta recibido');
        if (event.delta) {
          const audioBuffer = Buffer.from(event.delta, 'base64');
          this.audioHandlers.forEach(handler => handler(audioBuffer));
        }
        break;

      case 'response.audio.done':
      case 'response.output_audio.done':
        this.logger.log('‚úÖ Audio completo recibido');
        this.audioDoneHandlers.forEach(handler => handler());
        break;

      // Transcripci√≥n
      case 'conversation.item.input_audio_transcription.completed':
        this.logger.log(`üë§ Usuario: ${event.transcript}`);
        break;

      case 'conversation.item.input_audio_transcription.failed':
        // FIX: Concatenar error al mensaje para que el logger personalizado lo muestre
        this.logger.warn(`‚ö†Ô∏è Transcripci√≥n fallida: ${JSON.stringify(event.error, null, 2)}`);
        break;

      // VAD
      case 'input_audio_buffer.speech_started':
        this.logger.log('üéôÔ∏è Detectado inicio de habla del usuario (Interrupci√≥n)');
        
        // Barge-in: 
        // 1. Marcamos interrupci√≥n para ignorar paquetes "en vuelo" localmente
        // 2. Notificamos handlers para limpiar el buffer de audio local (aplay)
        // 3. Forzamos la cancelaci√≥n INMEDIATA en el servidor para evitar que 
        //    OpenAI siga procesando (y tardando) en generar la respuesta anterior.
        
        this.isInterrupted = true;
        
        if (this.isResponseActive) {
            this.sendEvent({ type: 'response.cancel' }); // Solo cancelar si hay algo que cancelar
        }
        
        this.speechStartedHandlers.forEach(handler => handler());
        break;

      case 'input_audio_buffer.speech_stopped':
        this.logger.log('üéôÔ∏è Detectado fin de habla del usuario');
        break;

      case 'input_audio_buffer.committed':
        this.logger.log('‚úÖ Audio del usuario confirmado');
        break;

      // Tool calls
      case 'response.function_call_arguments.delta':
        // Acumular argumentos si es necesario
        break;

      case 'response.function_call_arguments.done':
        this.handleToolCall(event);
        break;

      // Errores
      case 'error':
        // Log detallado de CUALQUIER error
        this.logger.error('‚ùå Error de OpenAI (Detalle Completo):', JSON.stringify(event, null, 2));
        if (event.error?.code) {
             this.logger.error(`Error Code: ${event.error.code} - Message: ${event.error.message}`);
        }
        break;

      default:
        // Log de eventos no manejados (para debugging)
        if (!type.includes('delta')) {
          this.logger.debug(`üì® Evento no manejado: ${type}`);
        }
    }
  }

  /**
   * Maneja llamadas a herramientas
   */
  private async handleToolCall(event: any): Promise<void> {
    const { name, call_id, arguments: argsString } = event;
    
    let args: any;
    try {
      args = JSON.parse(argsString);
    } catch (error) {
      this.logger.error('Error parseando argumentos de tool call:', error);
      return;
    }

    this.logger.log(`üîß Tool call: ${name}(${JSON.stringify(args)})`);

    try {
      let result: any;

      if (name === 'finalizar_llamada') {
        // Manejo local para finalizar_llamada
        this.logger.log('üìû Ejecutando tool local: finalizar_llamada');
        
        // Simular delay y desconexi√≥n
        setTimeout(() => {
          this.endConversation();
          // Opcional: desconectar completamente
          // this.disconnect(); 
        }, 12000); // 12 segundos para permitir despedida (aumentado desde 4s)

        result = {
          finalizada: true,
          mensaje: 'OK. La llamada se cerrar√° autom√°ticamente.'
        };
      } else {
        // Ejecutar tool en backend
        result = await this.websocketClient.executeTool(
          name,
          args,
          this.currentSessionId || 'unknown'
        );
      }

      // Enviar resultado de la herramienta
      this.sendEvent({
        type: 'conversation.item.create',
        item: {
          type: 'function_call_output',
          call_id,
          output: JSON.stringify(result)
        }
      });

      // Solicitar que el modelo procese el resultado, SOLO si no estamos finalizando
      if (name !== 'finalizar_llamada') {
         this.sendEvent({
           type: 'response.create'
         });
      } else {
         this.logger.log(`‚è≥ Tool finalizar_llamada completada. Esperando cierre...`);
      }

      this.logger.log(`‚úÖ Tool ${name} completada`);
    } catch (error) {
      this.logger.error(`Error en tool ${name}:`, error);
      
      // Enviar error
      this.sendEvent({
        type: 'conversation.item.create',
        item: {
          type: 'function_call_output',
          call_id,
          output: JSON.stringify({
            error: 'Error ejecutando herramienta',
            details: error instanceof Error ? error.message : 'Unknown error'
          })
        }
      });

      // Solicitar que el modelo procese el error
      this.sendEvent({
        type: 'response.create'
      });
    }
  }

  /**
   * Genera instrucciones detalladas para una casa espec√≠fica
   * Mismo prompt que en DigitalConciergeView.tsx
   */
  private getDetailedInstructions(houseNumber: string): string {
    return `Eres Sof√≠a, la conserje del Condominio San Lorenzo. Eres amable, c√°lida y conversacional. Tu trabajo es ayudar a los visitantes a ingresar al condominio de manera eficiente pero siempre con una sonrisa en la voz.

INFORMACI√ìN INICIAL:
- El visitante ya marc√≥ la casa de destino: ${houseNumber}
- YA conoces a d√≥nde va, NO preguntes por la casa/departamento nuevamente

PERSONALIDAD:
- Habla de manera natural y amigable, como si conversaras con un vecino
- Usa expresiones chilenas cotidianas: "¬øC√≥mo est√°s?", "Perfecto", "Genial", "S√∫per"
- S√© paciente y emp√°tica, especialmente si el visitante parece confundido
- Haz que la conversaci√≥n fluya naturalmente, no como un formulario rob√≥tico

FLUJO DE CONVERSACI√ìN (SIGUE ESTE ORDEN ESTRICTAMENTE):

1. SALUDO INICIAL (di esto EXACTAMENTE una sola vez):
   "¬°Hola! Bienvenido al Condominio San Lorenzo. Mi nombre es Sof√≠a y soy la conserje. Veo que deseas visitar la casa ${houseNumber}. ¬øC√≥mo te llamas?"

2. RECOPILACI√ìN DE DATOS (UNO POR UNO, en este orden):
   
   a) Nombre:
      - Espera la respuesta
      - Guarda con guardar_datos_visitante(nombre: "...")
      - Di: "Encantada [nombre]. ¬øMe podr√≠as dar tu RUT o pasaporte por favor?"
   
   b) RUT/Pasaporte:
      - Espera la respuesta
      - Guarda con guardar_datos_visitante(rut: "...")
      - Si el sistema responde con error (RUT inv√°lido):
        * Di amablemente: "Disculpa, el RUT que escuch√© no parece ser v√°lido. ¬øMe lo podr√≠as repetir por favor? Dilo d√≠gito por d√≠gito si es necesario."
        * Vuelve a intentar guardar el RUT
      - Si se guarda correctamente, di: "Perfecto. ¬øY un n√∫mero de tel√©fono de contacto?"
   
   c) Tel√©fono:
      - Espera la respuesta
      - Guarda con guardar_datos_visitante(telefono: "...")
      - Di: "Genial. ¬øVienes en veh√≠culo?"
   
   d) Veh√≠culo (PREGUNTA PRIMERO):
      - Si dice S√ç: "¬øMe podr√≠as decir la patente del veh√≠culo?"
        * Espera la respuesta
        * Guarda con guardar_datos_visitante(patente: "...")
      - Si dice NO: "Vale, sin problema."
        * NO preguntes por patente
        * NO llames a guardar_datos_visitante con el campo patente
        * Simplemente omite este dato y contin√∫a
      - Luego di: "¬øCu√°l es el motivo de tu visita?"
   
   e) Motivo:
      - Espera la respuesta
      - Guarda con guardar_datos_visitante(motivo: "...")
      - Di: "Excelente, d√©jame buscar al residente."

3. B√öSQUEDA Y NOTIFICACI√ìN:
   - Llama buscar_residente(casa: "${houseNumber}")
   - Si encuentra residentes:
     * El sistema devuelve un array "residentes" con TODOS los miembros de la familia
     * Extrae los IDs de TODOS los residentes del array
     * Llama notificar_residente(residentes_ids: ["id1", "id2", ...]) con TODOS los IDs
     * IMPORTANTE: Al llamar notificar_residente, la visita se crea AUTOM√ÅTICAMENTE en estado pendiente
     * Si hay m√∫ltiples residentes, di: "Perfecto, le he enviado una notificaci√≥n a todos los residentes de la casa. Estoy esperando su respuesta."
     * Si hay un solo residente, di: "Perfecto, le he enviado una notificaci√≥n a [nombre del residente]. Estoy esperando su respuesta."
   - Si NO encuentra:
     * Di: "Lo siento, no encuentro registrado a ning√∫n residente en la casa ${houseNumber}. ¬øEst√°s seguro del n√∫mero?"

4. ESPERA DE RESPUESTA:
   - Despu√©s de decir que est√°s esperando, NO digas NADA m√°s
   - NO menciones palabras como "silencio", "espera en silencio", etc.
   - Simplemente DETENTE y espera
   - El SISTEMA te enviar√° autom√°ticamente un mensaje cuando el residente responda

5. RESPUESTA DEL RESIDENTE (cuando recibas la notificaci√≥n del sistema):
   - Si APROB√ì:
     * La visita YA FUE CREADA y ahora est√° ACTIVA autom√°ticamente
     * NO necesitas llamar ninguna herramienta adicional
     * Di con entusiasmo: "¬°Buenas noticias [nombre]! El residente ha aprobado tu visita. Puedes ingresar al condominio. ¬°Que tengas un excelente d√≠a!"
     * INMEDIATAMENTE despu√©s de este mensaje, llama finalizar_llamada()
   - Si RECHAZ√ì:
     * La visita fue autom√°ticamente marcada como RECHAZADA
     * NO necesitas llamar ninguna herramienta adicional
     * Di con empat√≠a: "Lo lamento [nombre], pero el residente no puede recibirte en este momento. Te sugiero contactarlo directamente. Que tengas buen d√≠a."
     * INMEDIATAMENTE despu√©s de este mensaje, llama finalizar_llamada()

IMPORTANTE: Despu√©s de dar el mensaje de aprobaci√≥n o rechazo, DEBES llamar a finalizar_llamada() sin decir nada m√°s. No esperes respuesta del visitante.

REGLAS IMPORTANTES:
- NO te saltes pasos del flujo
- NO repitas preguntas que ya hiciste
- Espera la respuesta del visitante antes de continuar
- Guarda cada dato INMEDIATAMENTE despu√©s de recibirlo
- SIEMPRE incluye casa: "${houseNumber}" al guardar datos
- NO inventes respuestas del residente
- Despu√©s de notificar, espera EN SILENCIO (no digas que est√°s en silencio)
- Acepta datos en cualquier formato (el sistema los formatea autom√°ticamente)`;
  }

  /**
   * Inicia una conversaci√≥n con el n√∫mero de casa marcado
   */
  startConversation(houseNumber: string): void {
    if (this.conversationActive) {
      this.logger.warn('Ya hay una conversaci√≥n activa');
      return;
    }

    this.logger.log(`üéôÔ∏è Iniciando conversaci√≥n para casa ${houseNumber}`);
    
    this.conversationActive = true;
    this.targetHouse = houseNumber;
    
    // Agregar mensaje del sistema con contexto de la casa espec√≠fica
    // Seg√∫n documentaci√≥n: usar conversation.item.create para updates mid-stream
    this.logger.log('üì§ Agregando contexto de la casa al sistema...');
    this.sendEvent({
      type: 'conversation.item.create',
      item: {
        type: 'message',
        role: 'system',
        content: [
          {
            type: 'input_text',
            text: this.getDetailedInstructions(houseNumber)
          }
        ]
      }
    });
    
    // Solicitar respuesta inicial con instrucciones espec√≠ficas
    this.logger.log('üì§ Solicitando respuesta inicial...');
    this.sendEvent({
      type: 'response.create',
      response: {
        instructions: `El visitante ya marc√≥ la casa ${houseNumber}. Saluda brevemente y pregunta: ¬øC√≥mo te llamas?`
      }
    });
  }

  /**
   * Env√≠a audio capturado del micr√≥fono
   */
  sendAudio(audioBuffer: Buffer): void {
    if (!this.conversationActive || !this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return;
    }

    // Convertir Buffer a base64
    const base64Audio = audioBuffer.toString('base64');
    
    this.sendEvent({
      type: 'input_audio_buffer.append',
      audio: base64Audio
    });
  }

  /**
   * Finaliza conversaci√≥n
   */
  endConversation(): void {
    if (!this.conversationActive) {
      return;
    }

    this.logger.log('üõë Finalizando conversaci√≥n');
    
    this.conversationActive = false;
    this.targetHouse = null;
    
    // Notificar a los suscriptores (ej. AudioRouter) para que apaguen sus flujos y rel√©s
    this.conversationEndedHandlers.forEach(handler => handler());
    
    // NOTA: Eliminamos la creaci√≥n forzada de respuesta ('response.create')
    // para evitar que el agente se despida m√∫ltiples veces o intente "rellenar" el silencio.
  }

  /**
   * Registra un handler para audio recibido de OpenAI
   */
  onAudioReceived(handler: (audioBuffer: Buffer) => void): void {
    this.audioHandlers.push(handler);
  }

  /**
   * Registra un handler para cuando finaliza la reproducci√≥n de audio
   */
  onAudioResponseDone(handler: () => void): void {
    this.audioDoneHandlers.push(handler);
  }

  /**
   * Registra un handler para cuando el usuario empieza a hablar (interrupci√≥n)
   */
  onSpeechStarted(handler: () => void): void {
    this.speechStartedHandlers.push(handler);
  }

  /**
   * Registra un handler para cuando la conversaci√≥n finaliza (ej. por tool call)
   */
  onConversationEnded(handler: () => void): void {
    this.conversationEndedHandlers.push(handler);
  }

  /**
   * Verifica si hay conversaci√≥n activa
   */
  isActive(): boolean {
    return this.conversationActive;
  }

  /**
   * Desconecta de OpenAI y notifica al backend
   */
  async disconnect(): Promise<void> {
    if (this.conversationActive) {
      this.endConversation();
    }

    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }

    // Notificar al backend que finaliz√≥ la sesi√≥n
    if (this.currentSessionId) {
      // Limpiar listener de Socket.IO
      this.websocketClient.offEvent(`visitor:response:${this.currentSessionId}`);

      try {
        await axios.post(`${this.backendUrl}/api/v1/concierge/session/${this.currentSessionId}/end`, {
          finalStatus: 'completed',
        });
        this.logger.log(`‚úÖ Sesi√≥n ${this.currentSessionId} finalizada en el backend`);
      } catch (error: any) {
        this.logger.error(`Error finalizando sesi√≥n en backend: ${error.message}`);
      }
      this.currentSessionId = null;
    }
    
    this.logger.log('Desconectado de OpenAI');
  }

  /**
   * Limpieza
   */
  async cleanup(): Promise<void> {
    await this.disconnect();
  }
}
